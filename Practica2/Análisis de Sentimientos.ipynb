{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 2\n",
    "## Análisis de sentimientos \n",
    "<br>\n",
    "\n",
    "__Alumnos:__\n",
    "* __Frederick Ernesto Borges Noronha__\n",
    "* __Victor Manuel Cavero Gracia__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1.\n",
    "### Apartado A.\n",
    "\n",
    "Configura una partición train-test usando el 75% de los datos para entrenamiento y el 25% restante para test.\n",
    "\n",
    "Vamos a estudiar varias representaciones de bolsa de palabras, pero todas ellas utilizarán __countVectorizer__ con el diccionario que se crea a partir de los términos del propio corpus y la lista de palabras vacías (__stop_words__) que proporciona sklearn para el inglés. Las 4 posibilidades que estudiaremos surgen de combinar los siguientes 2 parámetros:\n",
    "\n",
    "* Bolsa de palabras binaria y bolsa de palabras con TF/IDF (parámetro binary).\n",
    "* Usando un rango de n-gramas de (1,1) y de (1,2) (parámetro __ngram_range__).\n",
    "\n",
    "Para cada una de esas 4 combinaciones entrenaremos dos clasificadores:\n",
    "\n",
    "1. Un clasificador naive bayes, eligiendo el más adecuado para cada caso.\n",
    "2. Un árbol de decisión buscando un valor óptimo para uno de los siguientes parámetros para que se maximice la tasa de aciertos en el conjunto de test: __max_depth__, __min_samples_leaf__ o __max_leaf_nodes__ (siempre el mismo).\n",
    "\n",
    "Analiza la tasa de aciertos de entrenamiento y test de los 2 clasificadores en las 4 representaciones de bolsa de palabras (8 configuraciones en total) y contesta a las siguientes preguntas:\n",
    "\n",
    "* ¿Hay un clasificador que sea superior al otro? ¿por qué crees que sucede?\n",
    "* Para cada clasificador, ¿tiene un efecto positivo el añadir “complejidad” a la vectorización? Es decir, añadir bigramas y añadir tf-idf. ¿Por qué crees que sucede este efecto positivo o la falta del mismo?\n",
    "\n",
    "Selecciona el mejor árbol de decisión y obtén las 25 variables con más poder discriminante:\n",
    "\n",
    "* ¿Predominan más las palabras de uno u otro sentimiento? ¿por qué? ¿hay ruido?\n",
    "\n",
    "Selecciona el mejor clasificador naive bayes y obtén las 25 variables con más presencia en cada clase:\n",
    "\n",
    "* ¿Tienen sentido las palabras seleccionadas? ¿hay ruido (palabras sin sentimiento o de sentimiento opuesto al esperado)? ¿por qué crees que suceden estos fenómenos?\n",
    "\n",
    "Finalmente, explica de manera razonada las conclusiones que has extraído de todo el estudio realizado en este apartado.\n",
    "\n",
    "### Apartado B.\n",
    "\n",
    "Toma el mejor clasificador Naive Bayes y el mejor árbol de decisión y analiza a fondo sus resultados en el conjunto de test.\n",
    "1. Analiza la precisión y la exhaustividad de cada clasificador en cada una de las clases (opiniones positivas y negativas).\n",
    "    * Para cada clasificador, ¿tiene un comportamiento homogéneo a la hora de clasificar ambas clases?\n",
    "    * ¿Cuáles son las fortalezas y debilidades de cada uno de los clasificadores?\n",
    "    * ¿Hay algún clasificador que sea mejor que el otro en todo?\n",
    "    * ¿Coinciden ambos clasificadores a la hora de clasificar mejor una clase que la otra?\n",
    "\n",
    "2. Pinta los 8 primeros niveles del árbol de decisión y comenta lo que ves.\n",
    "    * ¿Qué estructura tiene el árbol?\n",
    "    * ¿Cómo interpretas los niveles que has pintado? ¿tienen algún sentido con respecto a la tasa de aciertos, o la precisión y exhaustividad del clasificador? o ¿Hay nodos impuros?\n",
    "    \n",
    "3. Por cada clasificador identifica 2 críticas que hayan sido falsas positivas (malas críticas calificadas como buenas) y 2 críticas que han sido falsas negativas (buenas críticas clasificadas como malas). Analiza tanto su texto original, como el vector de palabras resultante (solamente los términos activos).\n",
    "    * ¿Por qué crees que ha fallado el clasificador en cada uno de los casos?\n",
    "    * ¿Se te ocurre alguna idea sobre cómo mejorar el clasificador de sentimiento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:\n",
    "A continuación se encuentran todos los imports de las librerias de las que haremos uso en esta práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "data = pd.read_csv('Datos/yelp_labelled.txt', sep=\"\\t\", header=None)\n",
    "train, test = tts(data, train_size=0.75, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0  1\n",
       "0                             Wow... Loved this place.  1\n",
       "1                                   Crust is not good.  0\n",
       "2            Not tasty and the texture was just nasty.  0\n",
       "3    Stopped by during the late May bank holiday of...  1\n",
       "4    The selection on the menu was great and so wer...  1\n",
       "..                                                 ... ..\n",
       "995  I think food should have flavor and texture an...  0\n",
       "996                           Appetite instantly gone.  0\n",
       "997  Overall I was not impressed and would not go b...  0\n",
       "998  The whole experience was underwhelming, and I ...  0\n",
       "999  Then, as if I hadn't wasted enough of my life ...  0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>The turkey and roast beef were bland.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>Spend your money and time some place else.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>Great atmosphere, friendly and fast service.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>If you stay in Vegas you must get breakfast he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Service is perfect and the family atmosphere i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>The food was delicious, our bartender was atte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>The Veggitarian platter is out of this world!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>This place is pretty good, nice little vibe in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>It was a huge awkward 1.5lb piece of cow that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Best Buffet in town, for the price you cannot ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0  1\n",
       "82               The turkey and roast beef were bland.  0\n",
       "991         Spend your money and time some place else.  0\n",
       "789       Great atmosphere, friendly and fast service.  1\n",
       "894  If you stay in Vegas you must get breakfast he...  1\n",
       "398  Service is perfect and the family atmosphere i...  1\n",
       "..                                                 ... ..\n",
       "106  The food was delicious, our bartender was atte...  1\n",
       "270      The Veggitarian platter is out of this world!  1\n",
       "860  This place is pretty good, nice little vibe in...  1\n",
       "435  It was a huge awkward 1.5lb piece of cow that ...  0\n",
       "102  Best Buffet in town, for the price you cannot ...  1\n",
       "\n",
       "[750 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the train data\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>If you haven't gone here GO NOW!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>Try them in the airport to experience some tas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>The restaurant is very clean and has a family ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>I personally love the hummus, pita, baklava, f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>Come hungry, leave happy and stuffed!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Sooooo good!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>I never come again.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>The sweet potato fries were very good and seas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>The pan cakes everyone are raving about taste ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Things that went wrong: - They burned the saga...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0  1\n",
       "521                   If you haven't gone here GO NOW!  1\n",
       "737  Try them in the airport to experience some tas...  1\n",
       "740  The restaurant is very clean and has a family ...  1\n",
       "660  I personally love the hummus, pita, baklava, f...  1\n",
       "411              Come hungry, leave happy and stuffed!  1\n",
       "..                                                 ... ..\n",
       "109                                      Sooooo good!!  1\n",
       "430                                I never come again.  0\n",
       "77   The sweet potato fries were very good and seas...  1\n",
       "84   The pan cakes everyone are raving about taste ...  0\n",
       "286  Things that went wrong: - They burned the saga...  0\n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the test data\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar teniamos __1000 filas__ en los `datos iniciales` y al generar las particiones de train y test se obtienen un conjunto de `train` de __750 filas__ (75%) y otro de`test` de __250 filas__ (25%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "# Tomamos los textos del conjunto de entrenamiento y los transformamos en \n",
    "# una matriz de datos (palabras) según el diccionario estándar\n",
    "train_vector_data=vectorizer.fit_transform(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '100', '12', '17', '1979', '20', '2007', '30', '30s', '35', '40', '40min', '45', '4ths', '5lb', '70', '85', '90', 'absolute', 'absolutely', 'absolutley', 'accident', 'accomodate', 'accordingly', 'accountant', 'acknowledged', 'actual', 'actually', 'added', 'affordable', 'afternoon', 'ago', 'ahead', 'airline', 'ala', 'allergy', 'amazing', 'ambiance', 'ambience', 'ample', 'andddd', 'angry', 'anymore', 'anytime', 'anyways', 'apart', 'apologize', 'apology', 'app', 'appalling', 'apparently', 'appealing', 'appetite', 'appetizer', 'appetizers', 'apple', 'area', 'aren', 'arepas', 'aria', 'array', 'arrived', 'arrives', 'arriving', 'ask', 'asked', 'asking', 'assure', 'ate', 'atmosphere', 'attached', 'attack', 'attention', 'attentive', 'attitudes', 'auju', 'authentic', 'average', 'avocado', 'avoid', 'avoided', 'away', 'awesome', 'awful', 'awkward', 'awkwardly', 'baby', 'bacon', 'bad', 'bagels', 'bakery', 'bamboo', 'bar', 'bare', 'barely', 'bargain', 'bartender', 'bartenders', 'baseball', 'basically', 'bathroom', 'bathrooms', 'batter', 'bay', 'bbq', 'bean', 'beans', 'beat', 'beautiful', 'beautifully', 'beauty', 'beef', 'beer', 'beers', 'begin', 'believe', 'bellies', 'belly', 'best', 'better', 'big', 'biggest', 'bird', 'biscuit', 'biscuits', 'bisque', 'bit', 'bitches', 'bite', 'bites', 'bits', 'black', 'blah', 'blame', 'bland', 'blanket', 'bloody', 'blown', 'blows', 'blue', 'boba', 'bodes', 'boiled', 'bone', 'book', 'boot', 'boring', 'bother', 'bouchon', 'bought', 'bowl', 'box', 'boy', 'boyfriend', 'boys', 'bread', 'break', 'breakfast', 'breaks', 'breeze', 'brick', 'bring', 'brings', 'brother', 'brought', 'brownish', 'brunch', 'bruschetta', 'bucks', 'buffet', 'buffets', 'building', 'buldogis', 'bunch', 'burger', 'burgers', 'burrittos', 'bus', 'business', 'bussell', 'busy', 'butter', 'bye', 'caballero', 'caesar', 'cafe', 'café', 'calamari', 'calligraphy', 'callings', 'came', 'camelback', 'cape', 'capers', 'car', 'care', 'caring', 'carly', 'cart', 'cartel', 'case', 'cash', 'cashew', 'cashier', 'casino', 'caterpillar', 'caught', 'cause', 'certainly', 'chai', 'chains', 'changing', 'char', 'charcoal', 'charming', 'cheap', 'cheated', 'check', 'checked', 'cheek', 'cheese', 'cheeseburger', 'cheesecurds', 'chef', 'chefs', 'chewy', 'chicken', 'chickens', 'chinese', 'chip', 'chipolte', 'chips', 'chocolate', 'choose', 'choux', 'chow', 'christmas', 'cibo', 'circumstances', 'claimed', 'class', 'classic', 'classics', 'classy', 'clean', 'close', 'closed', 'club', 'clue', 'cocktail', 'cocktails', 'coconut', 'cod', 'coffee', 'cold', 'colder', 'college', 'color', 'combination', 'combo', 'come', 'comfortable', 'coming', 'common', 'companions', 'company', 'complain', 'complaints', 'completely', 'compliments', 'condiment', 'connisseur', 'connoisseur', 'consider', 'considering', 'consistent', 'constructed', 'contain', 'contained', 'continue', 'convenient', 'cook', 'cooked', 'cooking', 'cool', 'cost', 'costco', 'cotta', 'count', 'couple', 'couples', 'coupons', 'course', 'court', 'cover', 'covered', 'covers', 'cow', 'coziness', 'crab', 'cranberry', 'craving', 'crawfish', 'crazy', 'cream', 'creamy', 'crema', 'crepe', 'crisp', 'crispy', 'crostini', 'crowd', 'crowds', 'crumby', 'crust', 'crusty', 'crystals', 'curry', 'customer', 'customers', 'customize', 'cut', 'cute', 'damn', 'dark', 'date', 'dates', 'day', 'dead', 'deal', 'dealing', 'decent', 'decide', 'decided', 'decor', 'decorated', 'deep', 'deeply', 'def', 'definately', 'definitely', 'degree', 'del', 'delicioso', 'delicious', 'delight', 'delightful', 'delights', 'delish', 'delivery', 'denny', 'describing', 'descriptions', 'deserves', 'desired', 'dessert', 'desserts', 'deuchebaggery', 'devine', 'did', 'didn', 'difference', 'different', 'dine', 'dining', 'dinner', 'dinners', 'dipping', 'dirt', 'dirty', 'disappoint', 'disappointed', 'disappointing', 'disappointment', 'disapppointment', 'disbelief', 'disgrace', 'disgraceful', 'disgusted', 'disgusting', 'dish', 'dishes', 'dispenser', 'disrespected', 'diverse', 'does', 'dog', 'doing', 'dollars', 'don', 'dont', 'donut', 'door', 'double', 'douchey', 'dough', 'downright', 'downside', 'downtown', 'drag', 'drastically', 'drawing', 'dreamed', 'drenched', 'dressed', 'dressing', 'dried', 'driest', 'drink', 'drinks', 'dripping', 'drive', 'driving', 'dry', 'duck', 'dude', 'duo', 'dusted', 'dylan', 'easily', 'eat', 'eaten', 'eating', 'edible', 'edinburgh', 'editing', 'eel', 'egg', 'eggplant', 'eggs', 'elegantly', 'elk', 'email', 'employee', 'employees', 'end', 'ended', 'english', 'enjoy', 'enjoyable', 'enjoyed', 'ensued', 'entire', 'entrees', 'equally', 'especially', 'establishment', 'ethic', 'eve', 'evening', 'event', 'events', 'excalibur', 'exceeding', 'excellent', 'exceptional', 'excuse', 'expanded', 'expect', 'expectations', 'expected', 'experience', 'experiencing', 'expert', 'exquisite', 'extensive', 'extra', 'extremely', 'eyed', 'eyes', 'fabulous', 'fact', 'fail', 'fair', 'fairly', 'falling', 'family', 'famous', 'fan', 'fancy', 'fantastic', 'far', 'fare', 'fast', 'fat', 'fav', 'favor', 'favorite', 'fear', 'feel', 'feeling', 'feels', 'fell', 'fella', 'felt', 'fiancé', 'figured', 'filet', 'fillet', 'filling', 'finally', 'fine', 'finger', 'finish', 'fireball', 'firehouse', 'fish', 'flair', 'flat', 'flavor', 'flavored', 'flavorful', 'flavorless', 'flavors', 'flavourful', 'flirting', 'flop', 'flower', 'fluffy', 'fly', 'folks', 'food', 'foods', 'foot', 'forever', 'forgetting', 'forth', 'forward', 'francisco', 'freaking', 'free', 'freezing', 'fresh', 'fridays', 'fried', 'friend', 'friendly', 'friends', 'fries', 'frozen', 'fruit', 'frustrated', 'fry', 'fs', 'fucking', 'fun', 'furthermore', 'garden', 'garlic', 'gas', 'gave', 'gc', 'gem', 'generic', 'generous', 'getting', 'giant', 'girlfriend', 'given', 'giving', 'glad', 'glance', 'gloves', 'gluten', 'godfathers', 'going', 'gold', 'golden', 'gone', 'good', 'google', 'gordon', 'got', 'gotten', 'gourmet', 'grain', 'grandmother', 'gratuity', 'grease', 'great', 'greatest', 'greek', 'green', 'greens', 'greeted', 'grill', 'grilled', 'gristle', 'grocery', 'gross', 'grossed', 'ground', 'group', 'groups', 'grow', 'guacamole', 'guess', 'guest', 'guests', 'guy', 'guys', 'gyro', 'gyros', 'ha', 'hadn', 'hair', 'half', 'hamburger', 'han', 'hand', 'handed', 'handled', 'handling', 'handmade', 'hands', 'hankering', 'happened', 'happier', 'happy', 'hard', 'hardly', 'hasn', 'hate', 'hated', 'haunt', 'having', 'hawaiian', 'head', 'heads', 'healthy', 'heard', 'heart', 'hearts', 'heat', 'held', 'hell', 'hella', 'hello', 'help', 'helped', 'helpful', 'hereas', 'hi', 'high', 'highlight', 'highlighted', 'highlights', 'highly', 'hilarious', 'hip', 'hiro', 'hit', 'hole', 'home', 'homemade', 'honeslty', 'honest', 'honestly', 'honor', 'hooked', 'hope', 'hopefully', 'hopes', 'horrible', 'hospitality', 'host', 'hostess', 'hot', 'hottest', 'hour', 'hours', 'house', 'huevos', 'huge', 'human', 'humiliated', 'hunan', 'husband', 'hut', 'ians', 'ice', 'iced', 'idea', 'ignore', 'ignored', 'imagination', 'imagine', 'imagined', 'immediately', 'impeccable', 'impressed', 'impressive', 'inch', 'including', 'inconsiderate', 'incredible', 'incredibly', 'indicate', 'indoor', 'industry', 'inexpensive', 'inflate', 'informative', 'ingredients', 'insanely', 'inside', 'inspired', 'instantly', 'instead', 'insulted', 'insults', 'interesting', 'ironman', 'isn', 'item', 'jalapeno', 'jamaican', 'japanese', 'jerk', 'job', 'joey', 'join', 'joint', 'joke', 'joy', 'judge', 'judging', 'juice', 'juries', 'just', 'kept', 'key', 'khao', 'kid', 'kiddos', 'kids', 'killer', 'kind', 'know', 'known', 'lack', 'lacked', 'ladies', 'lady', 'large', 'largely', 'larger', 'lastly', 'late', 'later', 'latte', 'law', 'lawyers', 'leather', 'leave', 'leaves', 'left', 'leftover', 'legit', 'legs', 'lemon', 'let', 'letdown', 'letting', 'lettuce', 'level', 'life', 'lighter', 'lighting', 'lightly', 'like', 'liked', 'likes', 'liking', 'limited', 'lined', 'list', 'listed', 'literally', 'little', 'live', 'lived', 'll', 'lobster', 'located', 'location', 'long', 'longer', 'look', 'looked', 'looking', 'looks', 'lordy', 'lost', 'lot', 'lots', 'loudly', 'love', 'loved', 'lovely', 'lover', 'lovers', 'loves', 'loving', 'low', 'lox', 'loyal', 'luke', 'lukewarm', 'lunch', 'mac', 'macarons', 'madison', 'magazine', 'magic', 'main', 'maine', 'mains', 'maintaining', 'make', 'making', 'mall', 'man', 'management', 'manager', 'mandalay', 'mango', 'margaritas', 'maria', 'market', 'marrow', 'martini', 'mary', 'massive', 'maybe', 'mayo', 'meal', 'meals', 'mean', 'means', 'meat', 'meatloaf', 'meats', 'mediocre', 'mediterranean', 'meet', 'meh', 'mein', 'melt', 'melted', 'memory', 'menu', 'menus', 'mesquite', 'mess', 'metro', 'mexican', 'mgm', 'mid', 'middle', 'milk', 'milkshake', 'min', 'mind', 'minutes', 'miss', 'missed', 'mistake', 'mmmm', 'modern', 'moist', 'mojitos', 'mom', 'money', 'monster', 'months', 'mood', 'moods', 'mouth', 'mouthful', 'mouths', 'movies', 'moz', 'mozzarella', 'muffin', 'multi', 'multiple', 'music', 'mussels', 'nachos', 'nan', 'nargile', 'nasty', 'nay', 'neat', 'need', 'needed', 'needless', 'needs', 'neighborhood', 'new', 'nice', 'nicest', 'night', 'nigiri', 'noca', 'non', 'noodles', 'north', 'note', 'nude', 'number', 'nutshell', 'nyc', 'obviously', 'offered', 'offers', 'officially', 'oh', 'oil', 'ok', 'old', 'older', 'olives', 'omg', 'ones', 'onion', 'opened', 'operation', 'opinion', 'opportunity', 'options', 'order', 'ordered', 'ordering', 'orders', 'original', 'otto', 'outdoor', 'outrageously', 'outside', 'outstanding', 'outta', 'oven', 'overall', 'overcooked', 'overpriced', 'overwhelmed', 'owned', 'owner', 'owners', 'oysters', 'pace', 'packed', 'paid', 'pale', 'palm', 'pancake', 'pancakes', 'panna', 'paper', 'papers', 'par', 'paradise', 'parents', 'parties', 'party', 'passed', 'past', 'pasta', 'pastas', 'pastry', 'patio', 'patron', 'patty', 'pay', 'paying', 'peach', 'peanuts', 'peas', 'pecan', 'penne', 'people', 'pepper', 'perfect', 'perfection', 'perfectly', 'performed', 'perpared', 'person', 'personable', 'petty', 'phenomenal', 'philadelphia', 'pho', 'phoenix', 'picture', 'pictures', 'piece', 'pile', 'pineapple', 'pink', 'pita', 'pizza', 'pizzas', 'place', 'placed', 'places', 'plain', 'plate', 'platter', 'playing', 'pleasant', 'pleased', 'pleasure', 'pneumatic', 'point', 'poop', 'poor', 'poorly', 'pop', 'pork', 'portion', 'portions', 'positive', 'possible', 'postinos', 'potato', 'potatoes', 'poured', 'powdered', 'power', 'prefer', 'prepare', 'prepared', 'preparing', 'presentation', 'pretty', 'price', 'priced', 'prices', 'pricey', 'pricing', 'prime', 'privileged', 'probably', 'proclaimed', 'professional', 'profiterole', 'profound', 'promise', 'properly', 'pros', 'proven', 'provided', 'provides', 'providing', 'public', 'publicly', 'pumpkin', 'puree', 'puréed', 'quaint', 'qualified', 'quality', 'quick', 'quickly', 'quit', 'quite', 'ramsey', 'ranch', 'rancheros', 'rapidly', 'rare', 'rarely', 'raspberry', 'rated', 'ravoli', 'readers', 'real', 'realized', 'really', 'reasonable', 'reasonably', 'reasons', 'received', 'receives', 'recently', 'recommend', 'recommendation', 'recommended', 'recommending', 'red', 'redeeming', 'reduction', 'refill', 'refrained', 'refried', 'refused', 'regular', 'regularly', 'reheated', 'relationship', 'relax', 'relaxed', 'relleno', 'relocated', 'remember', 'reminds', 'replenished', 'requested', 'restaraunt', 'restaurant', 'restaurants', 'return', 'returned', 'returning', 'review', 'reviewing', 'reviews', 'revisiting', 'rge', 'ri', 'rib', 'ribeye', 'rice', 'rich', 'right', 'rings', 'rinse', 'risotto', 'roast', 'roasted', 'rock', 'roll', 'rolled', 'rolls', 'room', 'rotating', 'round', 'rowdy', 'rubber', 'rude', 'rudely', 'running', 'rushed', 'ryan', 'sad', 'sadly', 'saffron', 'said', 'salad', 'salads', 'salmon', 'salsa', 'salt', 'salty', 'sample', 'san', 'sandwich', 'sashimi', 'sat', 'satifying', 'satisfied', 'sauce', 'sauces', 'sause', 'saving', 'say', 'saying', 'says', 'scallop', 'scene', 'scottsdale', 'screams', 'screwed', 'seafood', 'seasonal', 'seasoning', 'seat', 'seated', 'seating', 'second', 'section', 'selection', 'selections', 'self', 'send', 'sense', 'sergeant', 'seriously', 'serivce', 'served', 'server', 'servers', 'serves', 'service', 'services', 'serving', 'set', 'setting', 'sever', 'sewer', 'sexy', 'shall', 'sharply', 'shawarrrrrrma', 'shirt', 'shocked', 'shoe', 'shoots', 'shop', 'shopping', 'shops', 'shots', 'shouldn', 'shower', 'shrimp', 'sick', 'sides', 'sign', 'signs', 'silently', 'similar', 'similarly', 'simple', 'simply', 'single', 'sitting', 'slaw', 'slices', 'slow', 'small', 'smaller', 'smashburger', 'smeared', 'smelled', 'smells', 'smoke', 'smooth', 'smoothies', 'soggy', 'soi', 'solidify', 'somethat', 'son', 'songs', 'soon', 'soooo', 'soooooo', 'sore', 'sorely', 'sound', 'soup', 'soups', 'sour', 'southwest', 'space', 'spaghetti', 'special', 'spend', 'spends', 'spice', 'spicier', 'spicy', 'spinach', 'sporting', 'spot', 'spotty', 'spring', 'sprouts', 'staff', 'stale', 'standard', 'star', 'stars', 'started', 'starving', 'station', 'stay', 'stayed', 'staying', 'steak', 'steakhouse', 'steaks', 'steiners', 'step', 'stepped', 'sticks', 'stir', 'stood', 'stop', 'stopped', 'store', 'strawberry', 'street', 'stretch', 'strike', 'strings', 'strip', 'stuff', 'stuffed', 'stupid', 'style', 'styrofoam', 'subpar', 'subway', 'succulent', 'suck', 'sucked', 'sucker', 'sucks', 'sugar', 'sugary', 'summarize', 'summary', 'summer', 'sun', 'sunday', 'sunglasses', 'super', 'sure', 'surprise', 'sushi', 'sweet', 'swung', 'table', 'tables', 'taco', 'tacos', 'talk', 'talking', 'tap', 'tapas', 'tartar', 'taste', 'tasted', 'tasteless', 'tasty', 'tater', 'tea', 'teamwork', 'teeth', 'tell', 'temp', 'tender', 'tepid', 'terrible', 'texture', 'thai', 'thanks', 'thats', 'theft', 'thing', 'things', 'think', 'thirty', 'thoroughly', 'thought', 'thumbs', 'tigerlilly', 'time', 'times', 'tiny', 'tip', 'toast', 'toasted', 'today', 'told', 'tongue', 'tonight', 'took', 'topic', 'tops', 'total', 'totally', 'tots', 'touch', 'touched', 'town', 'tracked', 'traditional', 'transcendant', 'trap', 'treat', 'treated', 'tribute', 'tried', 'trimmed', 'trip', 'trippy', 'trips', 'try', 'trying', 'tucson', 'tummy', 'tuna', 'turkey', 'tv', 'twice', 'typical', 'unbelievable', 'undercooked', 'understand', 'underwhelming', 'unexperienced', 'unfortunately', 'uninspired', 'unique', 'unless', 'unprofessional', 'unreal', 'untoasted', 'upgrading', 'uploaded', 'use', 'used', 'usual', 'vacant', 'vain', 'valley', 'value', 'vanilla', 've', 'veal', 'vegan', 'vegas', 'vegetables', 'vegetarian', 'veggie', 'veggitarian', 'ventilation', 'venture', 'venturing', 'venue', 'verge', 'version', 'vibe', 'vinegrette', 'violinists', 'visit', 'visited', 'vodka', 'voodoo', 'voted', 'waaaaaayyyyyyyyyy', 'wait', 'waited', 'waiter', 'waiting', 'waitress', 'waitresses', 'walked', 'wall', 'walls', 'want', 'wanted', 'wants', 'warm', 'warmer', 'warnings', 'wasn', 'waste', 'wasted', 'wasting', 'watch', 'watched', 'water', 'watered', 'way', 'ways', 'wayyy', 'weak', 'website', 'wedges', 'week', 'weekend', 'weekly', 'weird', 'welcome', 'went', 'whatsoever', 'whelm', 'white', 'wide', 'wienerschnitzel', 'wife', 'wildly', 'wine', 'wines', 'wings', 'wire', 'wish', 'witnessed', 'won', 'wonderful', 'wontons', 'word', 'work', 'worker', 'workers', 'working', 'works', 'world', 'worries', 'worse', 'worst', 'worth', 'wouldn', 'wound', 'wow', 'wrap', 'wrapped', 'wrong', 'ya', 'yeah', 'year', 'years', 'yellow', 'yucky', 'yum', 'yummy', 'zero']\n",
      "Feature_names Length 1523\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "print(feature_names)\n",
    "print(\"Feature_names Length\", len(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La lista de palabras que se utilizará para realizar el analisis de sentimientos contienen `1523 palabras`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador Naive Bayes\n",
    "\n",
    "Para poder realizar un análisis de los resultados posteriores debemos calcular un Naive Bayes sin ninguno de los parametros que estamos ajustando (`binary` y `ngram_range`).\n",
    "\n",
    "Estos parametros tienen los siguientes valores por defecto:\n",
    "* `binary`. Por defecto: __False__.\n",
    "\n",
    "* `ngram_range`. Por defecto: __(1, 1)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer0 = CountVectorizer(stop_words='english')\n",
    "\n",
    "train_vector_data0 = vectorizer0.fit_transform(train[0])\n",
    "test_vector_data0 = vectorizer.transform(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes, porcentaje de aciertos en entrenamiento: 0.952\n",
      "Multinomial Naive Bayes, porcentaje de aciertos en test: 0.764\n"
     ]
    }
   ],
   "source": [
    "mnb_classifier0 = MultinomialNB()\n",
    "\n",
    "mnb_classifier0.fit(train_vector_data0, train[1])\n",
    "\n",
    "mnb_train_predictions0 = mnb_classifier0.predict(train_vector_data0)\n",
    "mnb_test_predictions0 = mnb_classifier0.predict(test_vector_data0)\n",
    "\n",
    "print(\"Multinomial Naive Bayes, porcentaje de aciertos en entrenamiento:\", np.mean(mnb_train_predictions0 == train[1]))\n",
    "print(\"Multinomial Naive Bayes, porcentaje de aciertos en test:\", np.mean(mnb_test_predictions0 == test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Bolsa de palabras binaria con Monogramas:__ (Código NB1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = CountVectorizer(stop_words='english', binary=True, ngram_range=(1,1))\n",
    "\n",
    "train_vector_data1 = vectorizer1.fit_transform(train[0])\n",
    "test_vector_data1 = vectorizer1.transform(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes, porcentaje de aciertos en entrenamiento: 0.9506666666666667\n",
      "Multinomial Naive Bayes, porcentaje de aciertos en test: 0.764\n"
     ]
    }
   ],
   "source": [
    "mnb_classifier1 = MultinomialNB()\n",
    "\n",
    "mnb_classifier1.fit(train_vector_data1, train[1])\n",
    "\n",
    "mnb_train_predictions1 = mnb_classifier1.predict(train_vector_data1)\n",
    "mnb_test_predictions1 = mnb_classifier1.predict(test_vector_data1)\n",
    "\n",
    "print(\"Multinomial Naive Bayes, porcentaje de aciertos en entrenamiento:\", np.mean(mnb_train_predictions1 == train[1]))\n",
    "print(\"Multinomial Naive Bayes, porcentaje de aciertos en test:\", np.mean(mnb_test_predictions1 == test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['NB1']\n",
    "train_means = [np.mean(mnb_train_predictions1 == train[1]) * 100]\n",
    "test_means = [np.mean(mnb_test_predictions1 == test[1]) * 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__¿Tiene un efecto positivo el añadir “complejidad” a la vectorización? ¿Por qué crees que sucede este\n",
    "efecto positivo o la falta del mismo?__\n",
    "\n",
    "|<center>PARTICIÓN</center>|<center>REF</center>|<center>NB1</center>|\n",
    "|---------|---|---|\n",
    "|<center>**Train**</center>|<center>0.952</center>|<center>0.9506666666666667</center>|\n",
    "|<center>**Test**</center>|<center>0.764</center>|<center>0.764</center>|\n",
    "\n",
    "Como podemos observar, añadir los parametros para que funcione con bolsa de palabras binaria (`binary=True`) y con monogramas (`ngram_range=(1,1)`, esto no añade complejidad ya que es igual que el parametro por defecto), no producen una mejora en el resultado numérico, por lo contrario empeora la tasa de aciertos en test, pero no indica que sea un mal resultado, ya que quizas con esta implemetación se estan aprendiendo reglas que no correctas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Bolsa de palabras binaria con Monogramas y Bigramas:__ (Código NB2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = CountVectorizer(stop_words='english', binary=True, ngram_range=(1,2))\n",
    "\n",
    "train_vector_data2 = vectorizer2.fit_transform(train[0])\n",
    "test_vector_data2 = vectorizer2.transform(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes, porcentaje de aciertos en entrenamiento: 0.9773333333333334\n",
      "Multinomial Naive Bayes, porcentaje de aciertos en test: 0.772\n"
     ]
    }
   ],
   "source": [
    "mnb_classifier2 = MultinomialNB()\n",
    "\n",
    "mnb_classifier2.fit(train_vector_data2, train[1])\n",
    "\n",
    "mnb_train_predictions2 = mnb_classifier2.predict(train_vector_data2)\n",
    "mnb_test_predictions2 = mnb_classifier2.predict(test_vector_data2)\n",
    "\n",
    "print(\"Multinomial Naive Bayes, porcentaje de aciertos en entrenamiento:\", np.mean(mnb_train_predictions2 == train[1]))\n",
    "print(\"Multinomial Naive Bayes, porcentaje de aciertos en test:\", np.mean(mnb_test_predictions2 == test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels + ['NB2']\n",
    "train_means = train_means + [np.mean(mnb_train_predictions2 == train[1]) * 100]\n",
    "test_means = test_means + [np.mean(mnb_test_predictions2 == test[1]) * 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__¿Tiene un efecto positivo el añadir “complejidad” a la vectorización? ¿Por qué crees que sucede este\n",
    "efecto positivo o la falta del mismo?__\n",
    "\n",
    "|<center>PARTICIÓN</center>|<center>REF</center>|<center>NB2</center>|\n",
    "|---------|---|---|\n",
    "|<center>**Train**</center>|<center>0.952</center>|<center>0.9773333333333334</center>|\n",
    "|<center>**Test**</center>|<center>0.764</center>|<center>0.772</center>|\n",
    "\n",
    "Como podemos observar, añadir los parametros para que funcione con bolsa de palabras binaria (`binary=True`) y con monogramas y bigramas (`ngram_range=(1,2)`), ofrece una diferencia en el porcentaje de aciertos tanto en el conjunto de train como en el conjunto de test.\n",
    "\n",
    "Esto viene dado porque se usa la hipotesis de Markov para calcular la frecuenta de los bigramas y esto hace que los calculos realizados sean mas precisos que solo evaluar una palabra en un contexto determinado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Bolsa de palabras con TF/IDF con Monogramas:__ (Código NB3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer3 = CountVectorizer(stop_words='english', binary=False, ngram_range=(1,1))\n",
    "\n",
    "train_vector_data3=vectorizer3.fit_transform(train[0])\n",
    "\n",
    "tfidfer3= TfidfTransformer()\n",
    "\n",
    "# Calculamos el valor TF-IDF \n",
    "train_preprocessed3=tfidfer3.fit_transform(train_vector_data3)\n",
    "\n",
    "# Tomamos los textos del conjunto de test y los transformamos en una matriz\n",
    "# de palabras. Al usar \"transform\" toma como referencia únicamente las palabras\n",
    "# encontradas en el conjunto de entrenamiento\n",
    "test_vector_data3=vectorizer3.transform(test[0])\n",
    "# Calculamos el valor TF-IDF \n",
    "# Al usar \"transform\" toma como IDF el del conjunto de entrenamiento \n",
    "test_preprocessed3=tfidfer3.transform(test_vector_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes, porcentaje de aciertos en entrenamiento: 0.9613333333333334\n",
      "Multinomial Naive Bayes, porcentaje de aciertos en test: 0.772\n"
     ]
    }
   ],
   "source": [
    "mnb_classifier3 = MultinomialNB()\n",
    "\n",
    "mnb_classifier3.fit(train_preprocessed3, train[1])\n",
    "\n",
    "mnb_train_predictions3 = mnb_classifier3.predict(train_preprocessed3)\n",
    "mnb_test_predictions3 = mnb_classifier3.predict(test_preprocessed3)\n",
    "\n",
    "print(\"Multinomial Naive Bayes, porcentaje de aciertos en entrenamiento:\", np.mean(mnb_train_predictions3 == train[1]))\n",
    "print(\"Multinomial Naive Bayes, porcentaje de aciertos en test:\", np.mean(mnb_test_predictions3 == test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels + ['NB3']\n",
    "train_means = train_means + [np.mean(mnb_train_predictions3 == train[1]) * 100]\n",
    "test_means = test_means + [np.mean(mnb_test_predictions3 == test[1]) * 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__¿Tiene un efecto positivo el añadir “complejidad” a la vectorización? ¿Por qué crees que sucede este\n",
    "efecto positivo o la falta del mismo?__\n",
    "\n",
    "|<center>PARTICIÓN</center>|<center>REF</center>|<center>NB3</center>|\n",
    "|---------|---|---|\n",
    "|<center>**Train**</center>|<center>0.952</center>|<center>0.9613333333333334</center>|\n",
    "|<center>**Test**</center>|<center>0.764</center>|<center>0.772</center>|\n",
    "\n",
    "Como podemos observar, añadir los parametros para que funcione con bolsa de palabras con TF/IDF (`binary=False`) y con monogramas (`ngram_range=(1,1)`), ofrece una diferencia en el porcentaje de aciertos tanto en el conjunto de train como en el conjunto de test.\n",
    "\n",
    "Esto se debe al que al calcular con TF/IDF la bolsa de palabras la importancia de una palabra sea inversamente relativa a lo común que es en el documento, por tanto se obtiene una mejora en el clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Bolsa de palabras con TF/IDF con Monogramas y Bigramas:__ (Código NB4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer4 = CountVectorizer(stop_words='english', binary=False, ngram_range=(1,2))\n",
    "\n",
    "train_vector_data4 = vectorizer4.fit_transform(train[0])\n",
    "\n",
    "tfidfer4 = TfidfTransformer()\n",
    "\n",
    "# Calculamos el valor TF-IDF \n",
    "train_preprocessed4 = tfidfer4.fit_transform(train_vector_data4)\n",
    "\n",
    "# Tomamos los textos del conjunto de test y los transformamos en una matriz\n",
    "# de palabras. Al usar \"transform\" toma como referencia únicamente las palabras\n",
    "# encontradas en el conjunto de entrenamiento\n",
    "test_vector_data4 = vectorizer4.transform(test[0])\n",
    "# Calculamos el valor TF-IDF \n",
    "# Al usar \"transform\" toma como IDF el del conjunto de entrenamiento \n",
    "test_preprocessed4 = tfidfer4.transform(test_vector_data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes, porcentaje de aciertos en entrenamiento: 0.9893333333333333\n",
      "Multinomial Naive Bayes, porcentaje de aciertos en test: 0.784\n"
     ]
    }
   ],
   "source": [
    "mnb_classifier4 = MultinomialNB()\n",
    "\n",
    "mnb_classifier4.fit(train_preprocessed4, train[1])\n",
    "\n",
    "mnb_train_predictions4 = mnb_classifier4.predict(train_preprocessed4)\n",
    "mnb_test_predictions4 = mnb_classifier4.predict(test_preprocessed4)\n",
    "\n",
    "print(\"Multinomial Naive Bayes, porcentaje de aciertos en entrenamiento:\", np.mean(mnb_train_predictions4 == train[1]))\n",
    "print(\"Multinomial Naive Bayes, porcentaje de aciertos en test:\", np.mean(mnb_test_predictions4 == test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels + ['NB4']\n",
    "train_means = train_means + [np.mean(mnb_train_predictions4 == train[1]) * 100]\n",
    "test_means = test_means + [np.mean(mnb_test_predictions4 == test[1]) * 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__¿Tiene un efecto positivo el añadir “complejidad” a la vectorización? ¿Por qué crees que sucede este\n",
    "efecto positivo o la falta del mismo?__\n",
    "\n",
    "|<center>PARTICIÓN</center>|<center>REF</center>|<center>NB4</center>|\n",
    "|---------|---|---|\n",
    "|<center>**Train**</center>|<center>0.952</center>|<center>0.9893333333333333</center>|\n",
    "|<center>**Test**</center>|<center>0.764</center>|<center>0.784</center>|\n",
    "\n",
    "Como podemos observar, añadir los parametros para que funcione con bolsa de palabras con TF/IDF (`binary=False`) y con monogramas y bigramas (`ngram_range=(1,2)`), ofrece una diferencia en el porcentaje de aciertos tanto en el conjunto de train como en el conjunto de test.\n",
    "\n",
    "Esto se debe al que al calcular con TF/IDF la bolsa de palabras la importancia de una palabra sea inversamente relativa a lo común que es en el documento y además al utilizar monogramas y bigramas nos aseguramos de que no se evaluen las palabras unicamente de forma individual si no que también se tome en cuenta la palabra que le precede, todo esto permite que se obtenga una mejora en el clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparativa entre los clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.2 # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15, 10))\n",
    "rects1 = ax.bar(x - width/2, train_means, width, label='Train')\n",
    "rects2 = ax.bar(x + width/2, test_means, width, label='Test')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Porcentaje')\n",
    "ax.set_title('Evaluación de Naive Bayes')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{:.2f}%'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__¿Hay un clasificador que sea superior al otro? ¿por qué crees que sucede?__\n",
    "\n",
    "Como podemos apreciar en el gráfico de barras, el mejor clasificador que se tienen en Naive Bayes es el NB4 que  es el código con el que hemos llamado al clasificador con `Bolsa de palabras con TF/IDF con Monogramas y Bigramas` aunque la diferencia para los clasificadores de Naive Bayes es pequeña, pero podemos indicar el orden en el utilizariamos los mismos:\n",
    "\n",
    "1. NB4: `Bolsa de palabras con TF/IDF con Monogramas y Bigramas`.\n",
    "\n",
    "2. NB2: `Bolsa de palabras binaria con Monogramas y Bigramas`.\n",
    "\n",
    "3. NB3: `Bolsa de palabras con TF/IDF con Monogramas`.\n",
    "\n",
    "4. NB1: `Bolsa de palabras binaria con Monogramas`.\n",
    "\n",
    "Como hemos indicado anteriormente, el clasificador que utiliza bolsa de palabras con TF/IDF junto a monogramas y bigramas, ya que es la mejor combinación evaluada y esto se debe a que la importancia de una palabra es inversamente relativa a lo común que es en el documento y no se evaluan unicamente las palabras de forma individual si no que también se toma en cuenta la palabra que le precede."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árbol de decisión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer5 = CountVectorizer(stop_words='english')\n",
    "\n",
    "train_vector_data5 = vectorizer5.fit_transform(train[0])\n",
    "test_vector_data5 = vectorizer5.transform(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol, porcentaje de aciertos en entrenamiento: 0.9973333333333333\n",
      "Árbol, porcentaje de aciertos en test: 0.664\n"
     ]
    }
   ],
   "source": [
    "# Creamos el clasificador con los valores por defecto\n",
    "tree_classifier0 = tree.DecisionTreeClassifier(random_state=42)\n",
    "tree_classifier0.fit(train_vector_data5, train[1])\n",
    "\n",
    "tree_train_predictions0 = tree_classifier0.predict(train_vector_data5)\n",
    "tree_test_predictions0 = tree_classifier0.predict(test_vector_data5)\n",
    "\n",
    "\n",
    "print(\"Árbol, porcentaje de aciertos en entrenamiento:\", np.mean(tree_train_predictions0 == train[1]))\n",
    "print(\"Árbol, porcentaje de aciertos en test:\", np.mean(tree_test_predictions0 == test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Bolsa de palabras binaria con Monogramas:__ (Código AD1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer6 = CountVectorizer(stop_words='english', binary=True, ngram_range=(1,1))\n",
    "\n",
    "train_vector_data6 = vectorizer6.fit_transform(train[0])\n",
    "test_vector_data6 = vectorizer6.transform(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol, porcentaje de aciertos en entrenamiento: 0.9973333333333333\n",
      "Árbol, porcentaje de aciertos en test: 0.672\n"
     ]
    }
   ],
   "source": [
    "# Creamos el clasificador con los valores por defecto\n",
    "tree_classifier1 = tree.DecisionTreeClassifier(random_state=42)\n",
    "tree_classifier1.fit(train_vector_data6, train[1])\n",
    "\n",
    "tree_train_predictions1 = tree_classifier1.predict(train_vector_data6)\n",
    "tree_test_predictions1 = tree_classifier1.predict(test_vector_data6)\n",
    "\n",
    "\n",
    "print(\"Árbol, porcentaje de aciertos en entrenamiento:\", np.mean(tree_train_predictions1 == train[1]))\n",
    "print(\"Árbol, porcentaje de aciertos en test:\", np.mean(tree_test_predictions1 == test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2 = ['AD1']\n",
    "train_means2 = [np.mean(tree_train_predictions1 == train[1]) * 100]\n",
    "test_means2 = [np.mean(tree_test_predictions1 == test[1]) * 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__¿Tiene un efecto positivo el añadir “complejidad” a la vectorización? ¿Por qué crees que sucede este\n",
    "efecto positivo o la falta del mismo?__\n",
    "\n",
    "`RESPUESTA PENDIENTE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Bolsa de palabras binaria con Monogramas y Bigramas:__ (Código AD2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer7 = CountVectorizer(stop_words='english', binary=True, ngram_range=(1,2))\n",
    "\n",
    "train_vector_data7 = vectorizer7.fit_transform(train[0])\n",
    "test_vector_data7 = vectorizer7.transform(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol, porcentaje de aciertos en entrenamiento: 0.9973333333333333\n",
      "Árbol, porcentaje de aciertos en test: 0.672\n"
     ]
    }
   ],
   "source": [
    "# Creamos el clasificador con los valores por defecto\n",
    "tree_classifier2 = tree.DecisionTreeClassifier(random_state=42)\n",
    "tree_classifier2.fit(train_vector_data7, train[1])\n",
    "\n",
    "tree_train_predictions2 = tree_classifier2.predict(train_vector_data7)\n",
    "tree_test_predictions2 = tree_classifier2.predict(test_vector_data7)\n",
    "\n",
    "\n",
    "print(\"Árbol, porcentaje de aciertos en entrenamiento:\", np.mean(tree_train_predictions2 == train[1]))\n",
    "print(\"Árbol, porcentaje de aciertos en test:\", np.mean(tree_test_predictions2 == test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2 = labels2 + ['AD2']\n",
    "train_means2 = train_means2 + [np.mean(tree_train_predictions2 == train[1]) * 100]\n",
    "test_means2 = test_means2 + [np.mean(tree_test_predictions2 == test[1]) * 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__¿Tiene un efecto positivo el añadir “complejidad” a la vectorización? ¿Por qué crees que sucede este\n",
    "efecto positivo o la falta del mismo?__\n",
    "\n",
    "`RESPUESTA PENDIENTE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Bolsa de palabras con TF/IDF con Monogramas:__ (Código AD3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer8 = CountVectorizer(stop_words='english', binary=False, ngram_range=(1,1))\n",
    "\n",
    "train_vector_data8=vectorizer8.fit_transform(train[0])\n",
    "\n",
    "tfidfer8= TfidfTransformer()\n",
    "\n",
    "# Calculamos el valor TF-IDF \n",
    "train_preprocessed8=tfidfer8.fit_transform(train_vector_data8)\n",
    "\n",
    "# Tomamos los textos del conjunto de test y los transformamos en una matriz\n",
    "# de palabras. Al usar \"transform\" toma como referencia únicamente las palabras\n",
    "# encontradas en el conjunto de entrenamiento\n",
    "test_vector_data8=vectorizer8.transform(test[0])\n",
    "# Calculamos el valor TF-IDF \n",
    "# Al usar \"transform\" toma como IDF el del conjunto de entrenamiento \n",
    "test_preprocessed8=tfidfer8.transform(test_vector_data8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol, porcentaje de aciertos en entrenamiento: 0.9973333333333333\n",
      "Árbol, porcentaje de aciertos en test: 0.696\n"
     ]
    }
   ],
   "source": [
    "# Creamos el clasificador con los valores por defecto\n",
    "tree_classifier3 = tree.DecisionTreeClassifier(random_state=42)\n",
    "tree_classifier3.fit(train_preprocessed8, train[1])\n",
    "\n",
    "tree_train_predictions3 = tree_classifier3.predict(train_preprocessed8)\n",
    "tree_test_predictions3 = tree_classifier3.predict(test_preprocessed8)\n",
    "\n",
    "\n",
    "print(\"Árbol, porcentaje de aciertos en entrenamiento:\", np.mean(tree_train_predictions3 == train[1]))\n",
    "print(\"Árbol, porcentaje de aciertos en test:\", np.mean(tree_test_predictions3 == test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2 = labels2 + ['AD3']\n",
    "train_means2 = train_means2 + [np.mean(tree_train_predictions3 == train[1]) * 100]\n",
    "test_means2 = test_means2 + [np.mean(tree_test_predictions3 == test[1]) * 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__¿Tiene un efecto positivo el añadir “complejidad” a la vectorización? ¿Por qué crees que sucede este\n",
    "efecto positivo o la falta del mismo?__\n",
    "\n",
    "`RESPUESTA PENDIENTE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Bolsa de palabras con TF/IDF con Monogramas y Bigramas:__ (Código AD4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer9 = CountVectorizer(stop_words='english', binary=False, ngram_range=(1,2))\n",
    "\n",
    "train_vector_data9 = vectorizer9.fit_transform(train[0])\n",
    "\n",
    "tfidfer9 = TfidfTransformer()\n",
    "\n",
    "# Calculamos el valor TF-IDF \n",
    "train_preprocessed9 = tfidfer9.fit_transform(train_vector_data9)\n",
    "\n",
    "# Tomamos los textos del conjunto de test y los transformamos en una matriz\n",
    "# de palabras. Al usar \"transform\" toma como referencia únicamente las palabras\n",
    "# encontradas en el conjunto de entrenamiento\n",
    "test_vector_data9 = vectorizer9.transform(test[0])\n",
    "# Calculamos el valor TF-IDF \n",
    "# Al usar \"transform\" toma como IDF el del conjunto de entrenamiento \n",
    "test_preprocessed9 = tfidfer9.transform(test_vector_data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol, porcentaje de aciertos en entrenamiento: 0.9973333333333333\n",
      "Árbol, porcentaje de aciertos en test: 0.664\n"
     ]
    }
   ],
   "source": [
    "# Creamos el clasificador con los valores por defecto\n",
    "tree_classifier4 = tree.DecisionTreeClassifier(random_state=42)\n",
    "tree_classifier4.fit(train_preprocessed9, train[1])\n",
    "\n",
    "tree_train_predictions4 = tree_classifier4.predict(train_preprocessed9)\n",
    "tree_test_predictions4 = tree_classifier4.predict(test_preprocessed9)\n",
    "\n",
    "\n",
    "print(\"Árbol, porcentaje de aciertos en entrenamiento:\", np.mean(tree_train_predictions4 == train[1]))\n",
    "print(\"Árbol, porcentaje de aciertos en test:\", np.mean(tree_test_predictions4 == test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2 = labels2 + ['AD4']\n",
    "train_means2 = train_means2 + [np.mean(tree_train_predictions4 == train[1]) * 100]\n",
    "test_means2 = test_means2 + [np.mean(tree_test_predictions4 == test[1]) * 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__¿Tiene un efecto positivo el añadir “complejidad” a la vectorización? ¿Por qué crees que sucede este\n",
    "efecto positivo o la falta del mismo?__\n",
    "\n",
    "`RESPUESTA PENDIENTE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparativa entre los clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(labels2))  # the label locations\n",
    "width = 0.2 # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15, 10))\n",
    "rects1 = ax.bar(x - width/2, train_means2, width, label='Train')\n",
    "rects2 = ax.bar(x + width/2, test_means2, width, label='Test')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Porcentaje')\n",
    "ax.set_title('Evaluación de Árbol de Decisión')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels2)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{:.2f}%'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__¿Hay un clasificador que sea superior al otro? ¿por qué crees que sucede?__\n",
    "\n",
    "Como podemos apreciar en el gráfico de barras, el mejor clasificador que se generó con `Árboles de Decisión` es el AD3 que  es el código con el que hemos llamado al clasificador con `Bolsa de palabras con TF/IDF con Monogramas` aunque la diferencia para los clasificadores de Árboles de Decisión es pequeña, pero podemos indicar el orden en el utilizariamos los mismos:\n",
    "\n",
    "1. AD3: `Bolsa de palabras con TF/IDF con Monogramas`.\n",
    "\n",
    "2. AD1: `Bolsa de palabras binaria con Monogramas`.\n",
    "\n",
    "3. AD2: `Bolsa de palabras binaria con Monogramas y Bigramas`.\n",
    "\n",
    "4. AD4: `Bolsa de palabras con TF/IDF con Monogramas y Bigramas`.\n",
    "\n",
    "\n",
    "`RESPUESTA PENDIENTE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Palabras predominantes en el Árbol de Decisión con bolsa de palabras con TF/IDF y Monogramas\n",
    "\n",
    "El clasificador a utilizar es el `tree_classifier3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 features in the tree\n",
      "\n",
      "great good delicious best place nice amazing love friendly awesome excellent fantastic time perfect vegas\n"
     ]
    }
   ],
   "source": [
    "def print_topN_features_in_trees(vectorizer, clf, n=20):\n",
    "    \"\"\"Prints features with the highest coefficient values\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    \n",
    "    topN = np.argsort(clf.feature_importances_)[-n:]\n",
    "    reversed_top = topN[::-1]\n",
    "    print(\"Top {} features in the tree\\n\".format(n))\n",
    "    print(\"%s\" % ( \" \".join(feature_names[j] for j in reversed_top)))\n",
    "\n",
    "print_topN_features_in_trees(vectorizer,tree_classifier3,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__¿Predominan más las palabras de uno u otro sentimiento? ¿por qué? ¿hay ruido?__\n",
    "\n",
    "Hemos observado que predominan las palabras con sentimiento positivo, esto se debe a que el clasificador ha sobreaprendido reglas y busca pequeñas diferencias para decicir el sentimiento presente en el texto.\n",
    "\n",
    "Por otra parte, podemos observar que en el existe ruido con palabras como **place**, **time** y **vegas**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Palabras predominantes en Naive Bayes con bolsa de palabras con TF/IDF con Monogramas y Bigramas.\n",
    "\n",
    "El clasificador a utilizar es el `mnb_classifier4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 features per class\n",
      "\n",
      "Malo:   food place service don won like bad time good think probably did eating minutes going \n",
      "\n",
      "Bueno:   great good place food service delicious awesome amazing love friendly best nice really time just \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_topN_features_per_class_in_NB(vectorizer, clf, class_labels, n=20):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    print(\"Top {} features per class\\n\".format(n))\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        topN = np.argsort(clf.feature_log_prob_[i])[-n:]\n",
    "        reversed_top = topN[::-1]\n",
    "        \n",
    "        print(\"%s:   %s\" % (class_label,\n",
    "              \" \".join(feature_names[j] for j in reversed_top)),'\\n')\n",
    "\n",
    "class_labels = [\"Malo\",\"Bueno\"]\n",
    "print_topN_features_per_class_in_NB(vectorizer4,mnb_classifier4,class_labels, 15)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__¿Tienen sentido las palabras seleccionadas? ¿hay ruido (palabras sin sentimiento o de sentimiento opuesto al esperado)? ¿por qué crees que suceden estos fenómenos?__\n",
    "\n",
    "Como podemos observar en las listas anteriores, hay palabras que no tienen sentido como por ejemplo **food** que se encuentra en ambas listas.\n",
    "\n",
    "Además, si miramos el contenido de cada lista, podemos decir que:\n",
    "\n",
    "- Para las palabras que clasifican un texto como malo, solo encontramos dos palabras que pueden indicar que realmente es malo: **bad** y **probably**.\n",
    "\n",
    "- Sin embargo, para las palabras que clasifican un texto como bueno, la mayoria de las palabras indican que buenos sentimientos, aunque se tienen algunas que son ruido como **place**, **food**, **service**, **really**, **time** y **just**.\n",
    "\n",
    "Esto puede suceder porque el clasificador este sobreaprendiendo y busque pequeñas diferencias para clasificar los textos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
